\chapter{Nuts and bolts}
Before starting with the book's topic I want to explain how to set up an
efficient environment and some good practice which can improve the code's readability and quality.
As somebody will notice these methods are completely opposite to the general code style trends. I'll 
try to give the motivation for each rule. Anyway, in general because the SQL universe is a strange 
place this requires strange approach. In order to write and read effectively the SQL the coder should gain 
the capability to get a mental map  between the query's sections and the underlying logic. This can be 
facilitated using a clear and well defined formatting.\newline

\section{Code formatting}
The SQL language is based on statements. Each statement is terminated by a specific character, by default ; . PostgreSQL 
supports a minimal flow control over the results with the CASE construct but nothing sophisticated like an high level 
language can offer. In order to understand the logic of the SQL statements is very important to get the statements 
formatted in the same way the database execute them. We'll look to the SELECT, the DML and the DDL. Each of those 
queries need different formatting because each one have a particular logic. The elements in common are the following.

\begin{itemize}
 \item Tab separator of 7 spaces; It's equivalent to the SELECT word plus an extra space
 \item All the keywords must be in uppercase
 \item After a round bracket there is a carriage return and one tab indented 
\end{itemize}



\subsection{SELECT}
When processing a query the parser works backward. It starts from the innermost complete statements and moves upward to 
get the entire picture. There is one remarkable exception. The WITH statements are computed first because required in 
the rest of the query. Actually the WITH acts like a temporary table. In order to see immediately the way PostgreSQL 
processes the query the indention should follow the same logic. 






This is the way the PostgreSQL documentation describes the process clearly.

\begin{smallverbatim}
 

SELECT retrieves rows from zero or more tables. The general processing of SELECT is as follows:

1. All queries in the WITH list are computed. 
These effectively serve as temporary tables that can be referenced in the FROM list. 
A WITH query that is referenced more than once in FROM is computed only once. 


2. All elements in the FROM list are computed. 
(Each element in the FROM list is a real or virtual table.) 
If more than one element is specified in the FROM list, they are cross-joined together.


3. If the WHERE clause is specified, all rows that do not satisfy the condition 
are eliminated from the output. 


4. If the GROUP BY clause is specified, or if there are aggregate function calls, 
the output is combined into groups of rows that match on one or more values, 
and the results of aggregate functions are computed. 
If the HAVING clause is present, it eliminates groups that do not satisfy the 
given condition. 


5. The actual output rows are computed using the SELECT output expressions 
for each selected row or row group. 


6. SELECT DISTINCT eliminates duplicate rows from the result. 
SELECT DISTINCT ON eliminates rows that match on all the specified expressions. 
SELECT ALL (the default) will return all candidate rows, including duplicates. 


7. Using the operators UNION, INTERSECT, and EXCEPT, the output of more than one 
SELECT statement can be combined to form a single result set. 
The UNION operator returns all rows that are in one or both of the result sets. 
The INTERSECT operator returns all rows that are strictly in both result sets. 
The EXCEPT operator returns the rows that are in the first result set but not in the second. 
In all three cases, duplicate rows are eliminated unless ALL is specified. 
The noise word DISTINCT can be added to explicitly specify eliminating duplicate rows. 
Notice that DISTINCT is the default behavior here, even though ALL is the default for SELECT itself. 


8. If the ORDER BY clause is specified, the returned rows are sorted in the specified order. 
If ORDER BY is not given, the rows are returned in whatever order the system finds fastest to produce. 


9. If the LIMIT (or FETCH FIRST) or OFFSET clause is specified, the SELECT statement only returns 
a subset of the result rows. 

10. If FOR UPDATE, FOR NO KEY UPDATE, FOR SHARE or FOR KEY SHARE is specified, 
the SELECT statement locks the selected rows against concurrent updates. 

\end{smallverbatim}



\subsection{DML}

\subsection{DDL}

\section{Type based field name}


\section{The editor}
Unlikely many commercial RDBMS PostgreSQL, ships only with the command line client psql. There is a 
good quantity of third party clients with good support for the database features and a good connectivity 
layer. An exhaustive list of those clients can be found on the PostgreSQL wiki\newline
\href{https://wiki.postgresql.org/wiki/Community\_Guide\_to\_PostgreSQL\_GUI\_Tools}{
https://wiki.postgresql.org/wiki/Community\_Guide\_to\_PostgreSQL\_GUI\_Tools}. Is difficult to say 
which editor is the best. When I started learning PostgreSQL the only tool available were PGAdmin 2 and 
phpPgAdmin. I decided for the former and I welcomed the newer version PgAdmin 3. However I tested some of 
the other clients like TOra, SQL workbench and SQL Maestro and I never found the same confidence and ease 
of usage like PgAdmin 3. Whether is the tool of your choice this should have the following features.

\subsection{Native connector}
One of the reasons I do not like SQL workbench is the JDBC connector. For me writing and testing the SQL 
code is a quick process. I write the code which is run against the database, then I update the query, 
another run and so on. The client response in this method is absolutely important. The native connector 
have virtually no lag, except the disk/network bandwidth.



