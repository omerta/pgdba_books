\chapter{Nuts and bolts}
Before starting with the book's topic I want to explain how to set up an
efficient environment and some good practice which can improve the code's readability and quality.
As somebody will notice these methods are completely opposite to the general code style trends. I'll 
try to give the motivation for each rule. Anyway, in general because the SQL universe is a strange 
place this requires strange approach. In order to write and read effectively the SQL the coder should gain 
the capability to get a mental map  between the query's sections and the underlying logic. This can be 
facilitated using a clear and well defined formatting.\newline

\section{Code formatting}
SQL is a statement based language. Each statement is terminated by a specific character, by 
default the semi colon. PostgreSQL supports the CASE construct which offers some control over the data flow. In 
order to understand the logic of the SQL statements is very important to get the statements formatted in the same 
way the database execute them; For each specific type of query, the SELECT, the DML and the DDL, there is 
a different logic and therefore a specific set of formatting rules. The common elements are the following.

\begin{itemize}
 \item There is a tab separator of 7 spaces
 \item All the keywords are in upper case
 \item After a round bracket there is a carriage return and one tab indented 
\end{itemize}



\subsection{SELECT}
When processing a query the parser works backward. It starts from the deepest and innermost complete statements 
and moving upward to get the entire picture. There is one remarkable exception. The WITH statements are computed 
first because they are required in the other parts of the query. Actually the WITH acts like a temporary table. 
The following rules can improve the query readability. We'll first look to the SELECT section.

\begin{itemize}
 \item After the word SELECT there is a carriage return
 \item The field's list after the SELECT indent by one tab
 \item Each field is on a different line 
 \item Aliases are separated by one space after the field's name
 \item CASE and END indent to the same field's level
 \item WHEN and ELSE indent one tab stop from CASE
 \item The subqueries's surrounding brackets will indent to the same field's level
 \item The subqueries's contents will indent one tab from the brackets
 
\end{itemize}






This is the way the PostgreSQL documentation describes how the select is processed.

\begin{smallverbatim}
 

SELECT retrieves rows from zero or more tables. The general processing of SELECT is as follows:

1. All queries in the WITH list are computed. 
These effectively serve as temporary tables that can be referenced in the FROM list. 
A WITH query that is referenced more than once in FROM is computed only once. 


2. All elements in the FROM list are computed. 
(Each element in the FROM list is a real or virtual table.) 
If more than one element is specified in the FROM list, they are cross-joined together.


3. If the WHERE clause is specified, all rows that do not satisfy the condition 
are eliminated from the output. 


4. If the GROUP BY clause is specified, or if there are aggregate function calls, 
the output is combined into groups of rows that match on one or more values, 
and the results of aggregate functions are computed. 
If the HAVING clause is present, it eliminates groups that do not satisfy the 
given condition. 


5. The actual output rows are computed using the SELECT output expressions 
for each selected row or row group. 


6. SELECT DISTINCT eliminates duplicate rows from the result. 
SELECT DISTINCT ON eliminates rows that match on all the specified expressions. 
SELECT ALL (the default) will return all candidate rows, including duplicates. 


7. Using the operators UNION, INTERSECT, and EXCEPT, the output of more than one 
SELECT statement can be combined to form a single result set. 
The UNION operator returns all rows that are in one or both of the result sets. 
The INTERSECT operator returns all rows that are strictly in both result sets. 
The EXCEPT operator returns the rows that are in the first result set but not in the second. 
In all three cases, duplicate rows are eliminated unless ALL is specified. 
The noise word DISTINCT can be added to explicitly specify eliminating duplicate rows. 
Notice that DISTINCT is the default behavior here, even though ALL is the default for SELECT itself. 


8. If the ORDER BY clause is specified, the returned rows are sorted in the specified order. 
If ORDER BY is not given, the rows are returned in whatever order the system finds fastest to produce. 


9. If the LIMIT (or FETCH FIRST) or OFFSET clause is specified, the SELECT statement only returns 
a subset of the result rows. 

10. If FOR UPDATE, FOR NO KEY UPDATE, FOR SHARE or FOR KEY SHARE is specified, 
the SELECT statement locks the selected rows against concurrent updates. 

\end{smallverbatim}



\subsection{DML}

\subsection{DDL}

\section{Type based field name}


\section{The editor}
Unlikely many commercial RDBMS PostgreSQL, ships only with the command line client psql. There is a 
good quantity of third party clients with good support for the database features and a good connectivity 
layer. An exhaustive list of those clients can be found on the PostgreSQL wiki\newline
\href{https://wiki.postgresql.org/wiki/Community\_Guide\_to\_PostgreSQL\_GUI\_Tools}{
https://wiki.postgresql.org/wiki/Community\_Guide\_to\_PostgreSQL\_GUI\_Tools}. Is difficult to say 
which editor is the best. When I started learning PostgreSQL the only tool available were PGAdmin 2 and 
phpPgAdmin. I decided for the former and I welcomed the newer version PgAdmin 3. However I tested some of 
the other clients like TOra, SQL workbench and SQL Maestro and I never found the same confidence and ease 
of usage like PgAdmin 3. Whether is the tool of your choice this should have the following features.

\subsection{Native connector}
One of the reasons I do not like SQL workbench is the JDBC connector. For me writing and testing the SQL 
code is a quick process. I write the code which is run against the database, then I update the query, 
another run and so on. The client response in this method is absolutely important. The native connector 
have virtually no lag, except the disk/network bandwidth.



